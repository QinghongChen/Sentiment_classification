{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLines(path):\n",
    "    result = []\n",
    "    file = open(path,'r', encoding='UTF-8')\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    temp = 0\n",
    "    for line in lines:\n",
    "        temp += 1\n",
    "        if(temp<len(lines)):\n",
    "            result.append(line[:-1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词，去除停用词\n",
    "def sen2word(sentence):\n",
    "    segList = jieba.cut(sentence)\n",
    "    preSegResult = []\n",
    "    for seg in segList:\n",
    "        preSegResult.append(seg)\n",
    "\n",
    "    stopwords = readLines('./dict/哈工大停用词表扩展.txt')\n",
    "    \n",
    "    segResult = []\n",
    "    for seg in preSegResult:\n",
    "        if seg in stopwords:\n",
    "            continue\n",
    "        else:\n",
    "            segResult.append(seg)\n",
    "      \n",
    "    return segResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\pc\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.015 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['你好', '很', '好', '有点', '小', '感冒']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen2word('你好吗，我很好，只是有点小感冒')\n",
    "# Input: '你好吗，我很好，只是有点小感冒'\n",
    "# preSegResult: ['你好', '吗', '，', '我', '很', '好', '，', '只是', '有点', '小', '感冒']\n",
    "# segResult:['你好', '很', '好', '有点', '小', '感冒']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list转dict\n",
    "def list_to_dict(word_list):\n",
    "    data = {}\n",
    "    for x in range(0, len(word_list)):\n",
    "        data[word_list[x]] = x\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_# 将词语分类并记录其位置\n",
    "def classify_words(word_dict):\n",
    "    # 情感词字典\n",
    "    sen_list = readLines('./dict/BosonNLP_sentiment_score.txt')\n",
    "    sen_dict = {}\n",
    "    for s in sen_list:\n",
    "        sen_dict[s.split(' ')[0]] = s.split(' ')[1]\n",
    "    # 否定词字典\n",
    "    not_word_list = readLines('./dict/否定词典/否定.txt')\n",
    "    # 程度副词字典\n",
    "    degree_list = readLines('./dict/知网Hownet情感词典/程度级别词语（中文）.txt')\n",
    "    degree_dic = {}\n",
    "    for d in degree_list:\n",
    "        degree_dic[d.split(',')[0]] = d.split(',')[1]\n",
    "    \n",
    "    # 分类\n",
    "    sen_word = dict()\n",
    "    not_word = dict()\n",
    "    degree_word = dict()\n",
    "    \n",
    "    for word in word_dict.keys():\n",
    "        if word in sen_dict.keys() and word not in not_word_list and word not in degree_dic.keys():\n",
    "            # 找出分词结果中在情感字典中的词\n",
    "            sen_word[word_dict[word]] = sen_dict[word]\n",
    "        elif word in not_word_list and word not in degree_dic.keys():\n",
    "            # 分词结果中在否定词列表中的词\n",
    "            not_word[word_dict[word]] = -1\n",
    "        elif word in degree_dic.keys():\n",
    "            # 分词结果中在程度副词中的词\n",
    "            degree_word[word_dict[word]] = degree_dic[word]\n",
    "    \n",
    "    return sen_word, not_word, degree_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: '-2.7582653803'}, {}, {0: '1.25'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_words({'你好':0, '很':0, '好':0, '有点':0, '小':0, '感冒':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_weight(sen_word, not_word, degree_word):\n",
    "    # 权重初始化为1\n",
    "    W = 1\n",
    "    # 将情感字典的key转为list\n",
    "    sen_word_index_list = list(sen_word.keys())\n",
    "    if len(sen_word_index_list) == 0:\n",
    "        return W\n",
    "    # 获取第一个情感词的下标，遍历从0到此位置之间的所有词，找出程度词和否定词\n",
    "    for i in range(0, sen_word_index_list[0]):\n",
    "        if i in not_word.keys():\n",
    "            W *= -1\n",
    "        elif i in degree_word.keys():\n",
    "            # 更新权重，如果有程度副词，分值乘以程度副词的程度分值\n",
    "            W *= float(degree_word[i])\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def socre_sentiment(sen_word, not_word, degree_word, seg_result):\n",
    "    \"\"\"计算得分\"\"\"\n",
    "    # 权重初始化为1\n",
    "    W = 1\n",
    "    score = 0\n",
    "    # 情感词下标初始化\n",
    "    sentiment_index = -1\n",
    "    # 情感词的位置下标集合\n",
    "    sentiment_index_list = list(sen_word.keys())\n",
    "    # 遍历分词结果(遍历分词结果是为了定位两个情感词之间的程度副词和否定词)\n",
    "    for i in range(0, len(seg_result)):\n",
    "        # 如果是情感词（根据下标是否在情感词分类结果中判断）\n",
    "        if i in sen_word.keys():\n",
    "            # 权重*情感词得分\n",
    "            score += W * float(sen_word[i])\n",
    "            # 情感词下标加1，获取下一个情感词的位置\n",
    "            sentiment_index += 1\n",
    "            if sentiment_index < len(sentiment_index_list) - 1:\n",
    "                # 判断当前的情感词与下一个情感词之间是否有程度副词或否定词\n",
    "                for j in range(sentiment_index_list[sentiment_index], sentiment_index_list[sentiment_index + 1]):\n",
    "                    # 更新权重，如果有否定词，取反\n",
    "                    if j in not_word.keys():\n",
    "                        W *= -1\n",
    "                    elif j in degree_word.keys():\n",
    "                        # 更新权重，如果有程度副词，分值乘以程度副词的程度分值\n",
    "                        W *= float(degree_word[j])\n",
    "        # 定位到下一个情感词\n",
    "        if sentiment_index < len(sentiment_index_list) - 1:\n",
    "            i = sentiment_index_list[sentiment_index + 1]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setiment_score(sententce):\n",
    "    seg_list = sen2word(sententce)\n",
    "    sen_word, not_word, degree_word = classify_words(list_to_dict(seg_list))\n",
    "    score = socre_sentiment(sen_word, not_word, degree_word, seg_list)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1884379423780018"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setiment_score('你好吗，我很好，只是有点小感冒')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
